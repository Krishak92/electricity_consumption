{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/train_df.csv\")\n",
    "df_test = pd.read_csv(\"data/test_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Pre-processing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the different scales between each features, we want to scale our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "columns_to_scale = ['Factor_A', 'Factor_B', 'Factor_C', 'Factor_D', 'Factor_E', 'Factor_F']\n",
    "df_train[columns_to_scale] = scaler.fit_transform(df_train[columns_to_scale])\n",
    "df_test[columns_to_scale] = scaler.transform(df_test[columns_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train['Date'] = pd.to_datetime(df_train['Date'])\n",
    "# df_test['Date'] = pd.to_datetime(df_test['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [df_train, df_test]:\n",
    "    df['Month'] = df.index.month\n",
    "    df['Day'] = df.index.day\n",
    "    df['Weekday'] = df.index.weekday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preparation modelisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = \"Electric_Consumption\"  \n",
    "feature_columns_train = [col for col in df_train.columns if col not in ['Date', target_column]] \n",
    "feature_columns_test = [col for col in df_test.columns if col not in ['Date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparation des séries temporelles\n",
    "train_target = df_train[target_column]\n",
    "train_features = df_train[feature_columns_train]\n",
    "test_features = df_test[feature_columns_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Modelisation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1 SARIMA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter les features exogènes (indépendantes) au modèle SARIMA\n",
    "exog_train = train_features.values\n",
    "exog_test = test_features.values\n",
    "\n",
    "# from pmdarima import auto_arima\n",
    "\n",
    "# # Recherche automatique des meilleurs paramètres SARIMA\n",
    "# best_model = auto_arima(\n",
    "#     train_target,\n",
    "#     exogenous=exog_train,\n",
    "#     seasonal=True,\n",
    "#     m=12,  # Période saisonnière\n",
    "#     start_p=0, max_p=3,  # Intervalle pour p\n",
    "#     start_q=0, max_q=3,  # Intervalle pour q\n",
    "#     start_P=0, max_P=2,  # Intervalle pour P\n",
    "#     start_Q=0, max_Q=2,  # Intervalle pour Q\n",
    "#     d=None, D=None,  # Détection automatique de d et D\n",
    "#     trace=True,  # Affiche les résultats pendant la recherche\n",
    "#     error_action='ignore',  # Ignorer les erreurs pour certaines configurations\n",
    "#     stepwise=True  # Recherche itérative\n",
    "# )\n",
    "\n",
    "# # Résumé du modèle\n",
    "# print(best_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "MissingDataError",
     "evalue": "exog contains inf or nans",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mMissingDataError\u001b[0m                          Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[31], line 2\u001b[0m\n",
      "\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Configuration du modèle SARIMA\u001b[39;00m\n",
      "\u001b[1;32m----> 2\u001b[0m sarima_model \u001b[38;5;241m=\u001b[39m \u001b[43mSARIMAX\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_target\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexog_train\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# Paramètres ARIMA (p, d, q)\u001b[39;49;00m\n",
      "\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseasonal_order\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Paramètres saisonniers (P, D, Q, S)\u001b[39;49;00m\n",
      "\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43menforce_stationarity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43menforce_invertibility\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n",
      "\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Entraîner le modèle\u001b[39;00m\n",
      "\u001b[0;32m     12\u001b[0m sarima_result \u001b[38;5;241m=\u001b[39m sarima_model\u001b[38;5;241m.\u001b[39mfit(disp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:328\u001b[0m, in \u001b[0;36mSARIMAX.__init__\u001b[1;34m(self, endog, exog, order, seasonal_order, trend, measurement_error, time_varying_regression, mle_regression, simple_differencing, enforce_stationarity, enforce_invertibility, hamilton_representation, concentrate_scale, trend_offset, use_exact_diffuse, dates, freq, missing, validate_specification, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, order\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m),\n",
      "\u001b[0;32m    319\u001b[0m              seasonal_order\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), trend\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "\u001b[0;32m    320\u001b[0m              measurement_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, time_varying_regression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m    325\u001b[0m              freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m, validate_specification\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "\u001b[0;32m    326\u001b[0m              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n",
      "\u001b[1;32m--> 328\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spec \u001b[38;5;241m=\u001b[39m \u001b[43mSARIMAXSpecification\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseasonal_order\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseasonal_order\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menforce_stationarity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menforce_invertibility\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconcentrate_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcentrate_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreq\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_specification\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_specification\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    333\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_params \u001b[38;5;241m=\u001b[39m SARIMAXParams(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spec)\n",
      "\u001b[0;32m    335\u001b[0m     \u001b[38;5;66;03m# Save given orders\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\tsa\\arima\\specification.py:446\u001b[0m, in \u001b[0;36mSARIMAXSpecification.__init__\u001b[1;34m(self, endog, exog, order, seasonal_order, ar_order, diff, ma_order, seasonal_ar_order, seasonal_diff, seasonal_ma_order, seasonal_periods, trend, enforce_stationarity, enforce_invertibility, concentrate_scale, trend_offset, dates, freq, missing, validate_specification)\u001b[0m\n",
      "\u001b[0;32m    441\u001b[0m         exog \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mc_[trend_data, exog]\n",
      "\u001b[0;32m    443\u001b[0m \u001b[38;5;66;03m# Create an underlying time series model, to handle endog / exog,\u001b[39;00m\n",
      "\u001b[0;32m    444\u001b[0m \u001b[38;5;66;03m# especially validating shapes, retrieving names, and potentially\u001b[39;00m\n",
      "\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# providing us with a time series index\u001b[39;00m\n",
      "\u001b[1;32m--> 446\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model \u001b[38;5;241m=\u001b[39m \u001b[43mTimeSeriesModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreq\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    447\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m faux_endog \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mendog\n",
      "\u001b[0;32m    449\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mexog\n",
      "\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:470\u001b[0m, in \u001b[0;36mTimeSeriesModel.__init__\u001b[1;34m(self, endog, exog, dates, freq, missing, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n",
      "\u001b[0;32m    468\u001b[0m     \u001b[38;5;28mself\u001b[39m, endog, exog\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dates\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n",
      "\u001b[0;32m    469\u001b[0m ):\n",
      "\u001b[1;32m--> 470\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    472\u001b[0m     \u001b[38;5;66;03m# Date handling in indexes\u001b[39;00m\n",
      "\u001b[0;32m    473\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_dates(dates, freq)\n",
      "\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\base\\model.py:270\u001b[0m, in \u001b[0;36mLikelihoodModel.__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n",
      "\u001b[1;32m--> 270\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    271\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize()\n",
      "\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\base\\model.py:95\u001b[0m, in \u001b[0;36mModel.__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n",
      "\u001b[0;32m     93\u001b[0m missing \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;32m     94\u001b[0m hasconst \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhasconst\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;32m---> 95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m     96\u001b[0m \u001b[43m                              \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m     97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_constant \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mk_constant\n",
      "\u001b[0;32m     98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mexog\n",
      "\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\base\\model.py:135\u001b[0m, in \u001b[0;36mModel._handle_data\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_handle_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, missing, hasconst, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n",
      "\u001b[1;32m--> 135\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mhandle_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    136\u001b[0m     \u001b[38;5;66;03m# kwargs arrays could have changed, easier to just attach here\u001b[39;00m\n",
      "\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m kwargs:\n",
      "\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\base\\data.py:675\u001b[0m, in \u001b[0;36mhandle_data\u001b[1;34m(endog, exog, missing, hasconst, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    672\u001b[0m     exog \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(exog)\n",
      "\u001b[0;32m    674\u001b[0m klass \u001b[38;5;241m=\u001b[39m handle_data_class_factory(endog, exog)\n",
      "\u001b[1;32m--> 675\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    676\u001b[0m \u001b[43m             \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\base\\data.py:88\u001b[0m, in \u001b[0;36mModelData.__init__\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n",
      "\u001b[0;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconst_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_constant \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;32m---> 88\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_constant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_integrity()\n",
      "\u001b[0;32m     90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache \u001b[38;5;241m=\u001b[39m {}\n",
      "\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\base\\data.py:134\u001b[0m, in \u001b[0;36mModelData._handle_constant\u001b[1;34m(self, hasconst)\u001b[0m\n",
      "\u001b[0;32m    132\u001b[0m exog_max \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(exog_max)\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[1;32m--> 134\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MissingDataError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexog contains inf or nans\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;32m    135\u001b[0m exog_min \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;32m    136\u001b[0m const_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(exog_max \u001b[38;5;241m==\u001b[39m exog_min)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "\n",
      "\u001b[1;31mMissingDataError\u001b[0m: exog contains inf or nans"
     ]
    }
   ],
   "source": [
    "#configuration modèle SARIMA\n",
    "sarima_model = SARIMAX(\n",
    "    endog=train_target,\n",
    "    exog=exog_train,\n",
    "    order=(3, 0, 2),            #paramètres ARIMA (p, d, q)\n",
    "    seasonal_order=(2, 0, 1, 12),  #paramètres saisonniers (P, D, Q, S)\n",
    "    enforce_stationarity=False,\n",
    "    enforce_invertibility=False\n",
    ")\n",
    "\n",
    "sarima_result = sarima_model.fit(disp=False)\n",
    "\n",
    "predictions = sarima_result.predict(\n",
    "    exog=exog_test\n",
    ")\n",
    "\n",
    "#ajout predictions dans le dataset\n",
    "df_test['Electric_Consumption'] = predictions\n",
    "\n",
    "#visualisation résultats\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df_train[target_column], label='Train Data', color='blue')\n",
    "plt.plot(df_test['Electric_Consumption'], label='SARIMA Predictions', color='green')\n",
    "plt.legend()\n",
    "plt.title('SARIMA Predictions vs Actual Data')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Target')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on retire \"Date\" comme index pour pouvoir étudier correctement le dataset avec LSTM ensuite\n",
    "df_test.reset_index(inplace=True)\n",
    "df_test[['Date', 'Electric_Consumption']].to_csv(\"results/predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2 LSTM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"data/test_df.csv\")\n",
    "df_test[columns_to_scale] = scaler.transform(df_test[columns_to_scale])\n",
    "df_test['Date'] = pd.to_datetime(df_test['Date'])\n",
    "df_test = df_test.sort_values(by='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = \"Electric_Consumption\"  \n",
    "feature_columns_train = [col for col in df_train.columns if col not in ['Date', target_column]] \n",
    "feature_columns_test = [col for col in df_test.columns if col not in ['Date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir la variable cible et les features\n",
    "X_train = df_train[feature_columns_train]  # Toutes les colonnes avant 'target'\n",
    "y_train = df_train[target_column]  # Colonne 'target'\n",
    "X_test = df_test[feature_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour créer des séquences\n",
    "print(\"Shape initiale de X_train :\", X_train.shape)\n",
    "print(\"Shape initiale de X_test :\", X_test.shape)\n",
    "def create_sequences(X, y, time_steps):\n",
    "    if len(X) <= time_steps:\n",
    "        raise ValueError(\"Le paramètre `time_steps` est trop grand pour la longueur des données.\")\n",
    "    \n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        X_seq.append(X[i:i + time_steps])\n",
    "        y_seq.append(y[i + time_steps])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "\n",
    "# Paramètre de séquencement (nombre de pas de temps)\n",
    "time_steps = 10\n",
    "\n",
    "# Créer les séquences\n",
    "X_train, y_train = create_sequences(X_train, y_train, time_steps)\n",
    "X_seq = []\n",
    "for i in range(len(X_test) - time_steps):\n",
    "        X_seq.append(X_test[i:i + time_steps])\n",
    "X_test = np.array(X_seq)\n",
    "\n",
    "print(\"Shape finale de X_train :\", X_train.shape)\n",
    "print(\"Shape finale de X_test :\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construire le modèle LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(units=1))  # Une sortie pour la prédiction de la target\n",
    "\n",
    "# Compiler le modèle\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Entraîner le modèle\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédire sur l'ensemble de test\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Si `predicted` est à 2 dimensions (par exemple, shape (2150, 1))\n",
    "if len(predicted) < len(df_test):\n",
    "    # Créer un padding de même forme que les prédictions\n",
    "    padding = np.full((len(df_test) - len(predicted), predicted.shape[1]), np.nan)  # Padding avec NaN\n",
    "    predicted = np.vstack([padding, predicted])  # Empiler verticalement\n",
    "\n",
    "# Vérification de la taille finale\n",
    "assert len(predicted) == len(df_test), \"Les tailles de `predicted` et `df_test` ne correspondent toujours pas.\"\n",
    "\n",
    "# Ajouter les prédictions au DataFrame\n",
    "df_test['Electric_Consumption'] = predicted.squeeze()  # Retirer les dimensions inutiles si nécessaire\n",
    "\n",
    "# Remplir les valeurs manquantes ou non valides\n",
    "df_test['Electric_Consumption'] = df_test['Electric_Consumption'].fillna(0)  # Remplacer NaN par 0 ou une autre valeur\n",
    "\n",
    "# Exportation au format CSV\n",
    "df_test[['Date', 'Electric_Consumption']].to_csv(\"results/predictions2.csv\", index=False)\n",
    "print(\"Exportation réussie.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
